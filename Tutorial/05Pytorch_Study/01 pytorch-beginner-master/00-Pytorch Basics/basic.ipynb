{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T01:44:41.119323Z",
     "start_time": "2019-02-27T01:44:40.805164Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T01:44:43.113964Z",
     "start_time": "2019-02-27T01:44:43.108975Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch 基本处理单元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T01:44:47.024441Z",
     "start_time": "2019-02-27T01:44:47.011487Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.],\n",
       "        [0., 0., 0., 0.]])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 返回的数组大小5x4的矩阵\n",
    "torch.Tensor(5, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T01:44:54.899037Z",
     "start_time": "2019-02-27T01:44:54.891055Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9395, 0.2675, 0.4903, 0.2578],\n",
       "        [0.8377, 0.7548, 0.5897, 0.9951],\n",
       "        [0.3166, 0.7359, 0.1234, 0.2832],\n",
       "        [0.8168, 0.7111, 0.3904, 0.6255],\n",
       "        [0.1712, 0.3807, 0.3037, 0.5572]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 返回的数组大小是5x4的矩阵，初始化是0~1的均匀分布\n",
    "torch.rand(5, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T01:45:11.098368Z",
     "start_time": "2019-02-27T01:45:11.091364Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([5, 4])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 得到矩阵大小\n",
    "a = torch.rand(5, 4)\n",
    "a.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T01:45:22.921735Z",
     "start_time": "2019-02-27T01:45:22.900796Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.],\n",
       "       [1., 1., 1., 1.]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy 类似的返回5x4大小的矩阵\n",
    "np.ones((5, 4))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T01:45:28.338252Z",
     "start_time": "2019-02-27T01:45:28.314316Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0.57740414 0.53184724 0.41207242 0.14435506]\n",
      " [0.99191034 0.6020316  0.5345968  0.7392254 ]\n",
      " [0.92170674 0.09100401 0.629193   0.18233329]\n",
      " [0.46986914 0.04344964 0.6349571  0.32299036]\n",
      " [0.9720333  0.5746105  0.90167856 0.28943193]]\n"
     ]
    }
   ],
   "source": [
    "# numpy 和 torch.Tensor 之间的转换\n",
    "# from Tensor to Numpy\n",
    "a = torch.rand(5, 4)\n",
    "b = a.numpy()\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T01:45:35.218879Z",
     "start_time": "2019-02-27T01:45:35.186974Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[3, 4],\n",
      "        [3, 6]], dtype=torch.int32)\n"
     ]
    }
   ],
   "source": [
    "# from Numpy to Tensor\n",
    "a = np.array([[3, 4], [3, 6]])\n",
    "b = torch.from_numpy(a)\n",
    "print(b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "运算和numpy类似"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T01:52:13.271693Z",
     "start_time": "2019-02-27T01:52:13.268718Z"
    }
   },
   "outputs": [],
   "source": [
    "x = torch.rand(5, 4)\n",
    "y = torch.rand(5, 4)\n",
    "c = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T01:52:17.803766Z",
     "start_time": "2019-02-27T01:52:17.795789Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[2.0844, 2.0193, 0.1426, 0.9634],\n",
      "        [2.0588, 0.8789, 1.2974, 2.7011],\n",
      "        [0.8467, 2.9199, 0.9122, 0.3748],\n",
      "        [2.0518, 2.6167, 1.8637, 0.5765],\n",
      "        [1.7241, 2.7067, 0.2687, 0.4826]])\n"
     ]
    }
   ],
   "source": [
    "print(c * x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T01:52:20.409225Z",
     "start_time": "2019-02-27T01:52:20.403241Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1383, 0.8924, 0.2364, 1.2413],\n",
      "        [1.2620, 0.8822, 0.4890, 1.6868],\n",
      "        [1.1702, 1.6065, 0.4789, 0.2381],\n",
      "        [1.3399, 1.1426, 1.2302, 1.1450],\n",
      "        [1.2268, 1.2695, 0.8977, 0.7646]])\n"
     ]
    }
   ],
   "source": [
    "print(x + y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T01:52:23.363425Z",
     "start_time": "2019-02-27T01:52:23.355463Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1383, 0.8924, 0.2364, 1.2413],\n",
      "        [1.2620, 0.8822, 0.4890, 1.6868],\n",
      "        [1.1702, 1.6065, 0.4789, 0.2381],\n",
      "        [1.3399, 1.1426, 1.2302, 1.1450],\n",
      "        [1.2268, 1.2695, 0.8977, 0.7646]])\n"
     ]
    }
   ],
   "source": [
    "print(x.add(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T01:52:28.028842Z",
     "start_time": "2019-02-27T01:52:28.003904Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.1383, 0.8924, 0.2364, 1.2413],\n",
       "        [1.2620, 0.8822, 0.4890, 1.6868],\n",
       "        [1.1702, 1.6065, 0.4789, 0.2381],\n",
       "        [1.3399, 1.1426, 1.2302, 1.1450],\n",
       "        [1.2268, 1.2695, 0.8977, 0.7646]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 可以直接进行操作改变原对象，x+y或者x.add()并不会改变x，但是x.add_()则会对x进行改变\n",
    "x.add_(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T01:52:37.483258Z",
     "start_time": "2019-02-27T01:52:37.475253Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[1.1383, 0.8924, 0.2364, 1.2413],\n",
      "        [1.2620, 0.8822, 0.4890, 1.6868],\n",
      "        [1.1702, 1.6065, 0.4789, 0.2381],\n",
      "        [1.3399, 1.1426, 1.2302, 1.1450],\n",
      "        [1.2268, 1.2695, 0.8977, 0.7646]])\n"
     ]
    }
   ],
   "source": [
    "print(x)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "将 torch.Tensor 放到 GPU 上"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T14:29:26.407056Z",
     "start_time": "2019-02-26T14:29:26.005881Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 判断一下电脑是否支持GPU\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-26T14:29:38.297261Z",
     "start_time": "2019-02-26T14:29:27.677692Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.5052, 0.0086, 0.2634, 0.1298],\n",
      "        [0.0589, 0.8489, 0.0683, 0.4833],\n",
      "        [0.3443, 0.4708, 0.1769, 0.1613],\n",
      "        [0.9588, 0.9737, 0.1310, 0.2063],\n",
      "        [0.7629, 0.4277, 0.5019, 0.6811]], device='cuda:0')\n"
     ]
    }
   ],
   "source": [
    "a = torch.rand(5, 4)\n",
    "a = a.cuda()\n",
    "print(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### torch 的自动求导功能\n",
    "torch 和大部分框架一样有着自动求导功能，对象不再是 torch.Tensor，而是torch.autograd.Variable\n",
    "\n",
    "本质上Variable和Tensor没有什么区别，不过Variable会放在一个计算图里面，可以进行前向传播和反向传播以及求导  \n",
    "\n",
    "![1.png](http://upload-images.jianshu.io/upload_images/3623720-1c2694b72e0341ce.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/1240)\n",
    "\n",
    "里面的creator表示通过什么操作得到的这个Variable，grad表示反向传播的梯度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T02:22:15.126634Z",
     "start_time": "2019-02-27T02:22:15.122645Z"
    }
   },
   "outputs": [],
   "source": [
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T02:22:16.316321Z",
     "start_time": "2019-02-27T02:22:16.283390Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([15.], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# requires_grad 表示是否对其求梯度，默认是False\n",
    "x = Variable(torch.Tensor([3]), requires_grad=True)\n",
    "y = Variable(torch.Tensor([5]), requires_grad=True)\n",
    "z = 2 * x + y + 4\n",
    "z"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T02:22:17.530733Z",
     "start_time": "2019-02-27T02:22:17.267812Z"
    }
   },
   "outputs": [],
   "source": [
    "# 对 x 和 y 分别求导\n",
    "z.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T02:22:18.301122Z",
     "start_time": "2019-02-27T02:22:18.292146Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dz/dx: tensor([2.])\n",
      "dz/dy: tensor([1.])\n"
     ]
    }
   ],
   "source": [
    "# x 的导数和 y 的导数\n",
    "print('dz/dx: {}'.format(x.grad.data))\n",
    "print('dz/dy: {}'.format(y.grad.data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-02-27T02:28:46.030205Z",
     "start_time": "2019-02-27T02:28:46.019221Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.7913, 1.7630, 0.0804],\n",
      "        [0.4106, 1.3172, 0.4514]], grad_fn=<MulBackward0>)\n",
      "tensor([[1.0000, 0.5000, 0.2500],\n",
      "        [2.0000, 2.0000, 2.0000]])\n"
     ]
    }
   ],
   "source": [
    "# 对矩阵的求导\n",
    "x = torch.rand([2,3])\n",
    "x = Variable(x, requires_grad = True)\n",
    "\n",
    "y = x * 2\n",
    "print(y)\n",
    "y.backward(torch.FloatTensor([[0.5, 0.25, 0.125],[1, 1, 1]]))\n",
    "print(x.grad.data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 神经网络部分\n",
    "\n",
    "所依赖的主要是 torch.nn 和 torch.nn.functional\n",
    "\n",
    "torch.nn 里面有着所有的神经网络的层的操作，其用来构建网络，只有执行一次网络的运算才执行一次\n",
    "\n",
    "torch.nn.functional 表示的是直接对其做一次向前运算操作"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本的网络构建类模板\n",
    "class net_name(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(net_name, self).__init__()\n",
    "        # 可以添加各种网络层\n",
    "        self.conv1 = nn.Conv2d(3, 10, 3)\n",
    "        # 具体每种层的参数可以去查看文档\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 定义向前传播\n",
    "        out = self.conv1(x)\n",
    "        return out"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
